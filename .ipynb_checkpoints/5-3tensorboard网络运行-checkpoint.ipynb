{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 14:47:30.064807 11136 deprecation.py:323] From <ipython-input-2-261f0ddcd227>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0717 14:47:30.069828 11136 deprecation.py:323] From D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0717 14:47:30.070792 11136 deprecation.py:323] From D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 14:47:30.309906 11136 deprecation.py:323] From D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0717 14:47:30.311862 11136 deprecation.py:323] From D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0717 14:47:30.360765 11136 deprecation.py:323] From D:\\Programs\\Anaconda\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter0,Testing Accurary 0.8295\n",
      "Iter1,Testing Accurary 0.8701\n",
      "Iter2,Testing Accurary 0.8823\n",
      "Iter3,Testing Accurary 0.8888\n",
      "Iter4,Testing Accurary 0.8938\n",
      "Iter5,Testing Accurary 0.8974\n",
      "Iter6,Testing Accurary 0.8996\n",
      "Iter7,Testing Accurary 0.9015\n",
      "Iter8,Testing Accurary 0.9033\n",
      "Iter9,Testing Accurary 0.9053\n",
      "Iter10,Testing Accurary 0.9064\n",
      "Iter11,Testing Accurary 0.9079\n",
      "Iter12,Testing Accurary 0.9081\n",
      "Iter13,Testing Accurary 0.9099\n",
      "Iter14,Testing Accurary 0.91\n",
      "Iter15,Testing Accurary 0.9104\n",
      "Iter16,Testing Accurary 0.9115\n",
      "Iter17,Testing Accurary 0.9126\n",
      "Iter18,Testing Accurary 0.9127\n",
      "Iter19,Testing Accurary 0.9133\n",
      "Iter20,Testing Accurary 0.9143\n",
      "Iter21,Testing Accurary 0.9141\n",
      "Iter22,Testing Accurary 0.9151\n",
      "Iter23,Testing Accurary 0.9158\n",
      "Iter24,Testing Accurary 0.9158\n",
      "Iter25,Testing Accurary 0.9162\n",
      "Iter26,Testing Accurary 0.9169\n",
      "Iter27,Testing Accurary 0.9177\n",
      "Iter28,Testing Accurary 0.918\n",
      "Iter29,Testing Accurary 0.9181\n",
      "Iter30,Testing Accurary 0.9175\n",
      "Iter31,Testing Accurary 0.9182\n",
      "Iter32,Testing Accurary 0.9182\n",
      "Iter33,Testing Accurary 0.9182\n",
      "Iter34,Testing Accurary 0.9189\n",
      "Iter35,Testing Accurary 0.9187\n",
      "Iter36,Testing Accurary 0.9191\n",
      "Iter37,Testing Accurary 0.9188\n",
      "Iter38,Testing Accurary 0.9195\n",
      "Iter39,Testing Accurary 0.9197\n",
      "Iter40,Testing Accurary 0.9191\n",
      "Iter41,Testing Accurary 0.9195\n",
      "Iter42,Testing Accurary 0.9209\n",
      "Iter43,Testing Accurary 0.9205\n",
      "Iter44,Testing Accurary 0.9207\n",
      "Iter45,Testing Accurary 0.9209\n",
      "Iter46,Testing Accurary 0.9211\n",
      "Iter47,Testing Accurary 0.9211\n",
      "Iter48,Testing Accurary 0.9212\n",
      "Iter49,Testing Accurary 0.921\n"
     ]
    }
   ],
   "source": [
    "# 载入数据库\n",
    "mnist = input_data.read_data_sets('MNIST_data',one_hot=True)\n",
    "\n",
    "# 每个批次的大小\n",
    "batch_size = 100\n",
    "# 计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples //batch_size\n",
    "\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean',mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var-mean)))\n",
    "        tf.summary.scalar('stddev',stddev)\n",
    "        tf.summary.scalar('max',tf.reduce_max(var))\n",
    "        tf.summary.scalar('min',tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram',var)\n",
    "        \n",
    "#命名空间\n",
    "with tf.name_scope('input'):\n",
    "    # 定义两个placeholder\n",
    "    x = tf.placeholder(tf.float32,[None,784],name='x-input')\n",
    "    y = tf.placeholder(tf.float32,[None,10],name='y-input')\n",
    "    \n",
    "with tf.name_scope('layer'):\n",
    "    # 创建一个简单的神经网络\n",
    "    with tf.name_scope('wights'):\n",
    "        W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "        variable_summaries(W)\n",
    "    with tf.name_scope('biases'):\n",
    "        b = tf.Variable(tf.zeros([10]),name='b')\n",
    "        variable_summaries(b)\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x,W)+b\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    # 定义二次代价函数\n",
    "    loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "    # loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "with tf.name_scope('train'):\n",
    "    # 使用梯度下降法\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "# 初始化变量\n",
    "init =  tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('accurary'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        # 结果存放在一个布尔型列表中\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) # argmax返回一维常量中最大值所在的位置\n",
    "    with tf.name_scope('accurary'):\n",
    "        # 求准确率\n",
    "        accurary = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accurary',accurary)\n",
    "        \n",
    "#合并所有的summary\n",
    "merged = tf.summary.merge(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for epoch in range(50):\n",
    "         for batch in range(n_batch):\n",
    "                batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "                sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "                summary = sess.run(merged,feed_dict={x:batch_xs,y:batch_ys})\n",
    "         writer.add_summary(summary,epoch)\n",
    "         acc = sess.run(accurary,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "         print(\"Iter\" + str(epoch) + \",Testing Accurary \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2001):\n",
    "    #m每个批次100个样本\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(100)\n",
    "    summary,_ = sess.run([merge,train_step],feed_dict={x:batch_xs,y:batch_ys})\n",
    "    writer.add_summary(summary,i)\n",
    "    if i%500==0:\n",
    "        print(sess.run(accurary,feed_dict={x:mnist.test.images,y:mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
